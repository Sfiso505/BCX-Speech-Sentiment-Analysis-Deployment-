{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Goal of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Where can it be used or which sectors could it be utilized?\n",
    "\n",
    "- Banking Industry call center.\n",
    "- Telecommunications Industry call center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How will this project help?\n",
    "\n",
    "1.1 Enhanced Customer Service: \n",
    "\n",
    "- It can to understand customer satisfaction levels, identify common issues, and improve overall service quality.\n",
    "\n",
    "1.2 Improved Call Routing: \n",
    "\n",
    "- It will also assist with routing angry or dissatisfied customers to specialized agents who excel in conflict resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your presentation, consider using visuals such as charts or graphs to illustrate potential improvements and benefits. Also, be prepared to provide examples or case studies from the call center industry that showcase the practical application and success of sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Presentation: Speech Sentiment Analysis\n",
    "\n",
    "## 1. Objective:\n",
    "\n",
    "Deploy a Speech Sentiment Analysis model for real-time emotion prediction.\n",
    "## 2. Architecture:\n",
    "\n",
    "### Flask Web App (Speech_Recognition_app.py):\n",
    "\n",
    "Loads the pre-trained model (entire_trained-model.h5).\n",
    "### Defines two endpoints:\n",
    "/predict: Accepts audio file uploads.\n",
    "/predict_audio: Accepts recorded audio data.\n",
    "Utilizes Librosa for audio preprocessing.\n",
    "### Model Inference (model_inference.py):\n",
    "\n",
    "Loads the pre-trained model.\n",
    "Preprocesses audio using Mel-Frequency Cepstral Coefficients (MFCC).\n",
    "Returns emotion prediction.\n",
    "### Front-end Script (script.js):\n",
    "\n",
    "Allows audio recording through the browser.\n",
    "Sends recorded audio to the Flask app for prediction using AJAX.\n",
    "## 3. Workflow:\n",
    "\n",
    "### User Interaction:\n",
    "\n",
    "User records or uploads an audio file through the web app.\n",
    "### Flask App:\n",
    "\n",
    "Temporarily saves the audio file (temp_audio.wav).\n",
    "Preprocesses audio using Librosa and sends it for prediction.\n",
    "### Model Inference:\n",
    "\n",
    "MFCC features extracted from audio.\n",
    "Features fed into the pre-trained model for emotion prediction.\n",
    "### Result Display:\n",
    "\n",
    "Predicted emotion displayed to the user.\n",
    "## 4. Endpoints:\n",
    "\n",
    "/predict: Expects a file upload.\n",
    "/predict_audio: Expects audio data.\n",
    "## 5. Ensuring Correctness:\n",
    "\n",
    "### Emotion Labels Order:\n",
    "\n",
    "Confirm that the emotion_labels list order in Speech_Recognition_app.py matches the model's output order.\n",
    "### AJAX Call and Endpoint:\n",
    "\n",
    "Verify that the AJAX call in script.js correctly targets the /predict_audio endpoint defined in the Flask app.\n",
    "## 6. Use Cases:\n",
    "\n",
    "Initially developed for Vodacom call center.\n",
    "Applicable in telecommunications and banking call centers.\n",
    "Potential Questions:\n",
    "\n",
    "How is audio processed for prediction?\n",
    "\n",
    "Audio is preprocessed using Librosa to extract MFCC features, which are then fed into the pre-trained model.\n",
    "Can you explain the workflow from user interaction to prediction?\n",
    "\n",
    "User records or uploads audio -> Flask app preprocesses -> MFCC features extracted -> Model predicts emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
